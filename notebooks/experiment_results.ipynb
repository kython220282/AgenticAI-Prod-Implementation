{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc229892",
   "metadata": {},
   "source": [
    "# Experiment Results Notebook\n",
    "\n",
    "This notebook is for documenting and comparing results from different experiments.\n",
    "\n",
    "**Use this notebook to:**\n",
    "- Compare different agent configurations\n",
    "- Analyze hyperparameter impact\n",
    "- Document experimental findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efba88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from utils import MetricsTracker\n",
    "\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd920a4b",
   "metadata": {},
   "source": [
    "## Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb652981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiments to compare\n",
    "experiments = {\n",
    "    'Experiment_1': {\n",
    "        'name': 'Baseline',\n",
    "        'learning_rate': 0.001,\n",
    "        'epsilon_decay': 0.995,\n",
    "        'results': []  # Will be populated\n",
    "    },\n",
    "    'Experiment_2': {\n",
    "        'name': 'Higher LR',\n",
    "        'learning_rate': 0.01,\n",
    "        'epsilon_decay': 0.995,\n",
    "        'results': []\n",
    "    },\n",
    "    'Experiment_3': {\n",
    "        'name': 'Faster Decay',\n",
    "        'learning_rate': 0.001,\n",
    "        'epsilon_decay': 0.99,\n",
    "        'results': []\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Experiment configurations loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5191845",
   "metadata": {},
   "source": [
    "## Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1242f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate experiment results\n",
    "# In practice, load from saved files\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "for exp_name, exp_config in experiments.items():\n",
    "    # Simulate results based on configuration\n",
    "    lr_factor = exp_config['learning_rate'] / 0.001\n",
    "    decay_factor = 1 - (1 - exp_config['epsilon_decay']) * 10\n",
    "    \n",
    "    results = []\n",
    "    for i in range(100):\n",
    "        reward = 10 + i * 0.5 * lr_factor * decay_factor + np.random.randn() * 5\n",
    "        results.append(reward)\n",
    "    \n",
    "    exp_config['results'] = results\n",
    "\n",
    "print(\"✓ Results loaded for all experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc7870",
   "metadata": {},
   "source": [
    "## Compare Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c623dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "\n",
    "for exp_name, exp_config in experiments.items():\n",
    "    results = exp_config['results']\n",
    "    comparison_data.append({\n",
    "        'Experiment': exp_config['name'],\n",
    "        'Learning Rate': exp_config['learning_rate'],\n",
    "        'Epsilon Decay': exp_config['epsilon_decay'],\n",
    "        'Mean Reward': np.mean(results),\n",
    "        'Std Reward': np.std(results),\n",
    "        'Max Reward': np.max(results),\n",
    "        'Final 10 Avg': np.mean(results[-10:])\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nExperiment Comparison:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c494279",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61b8153",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Learning curves comparison\n",
    "ax1 = axes[0, 0]\n",
    "for exp_name, exp_config in experiments.items():\n",
    "    results = exp_config['results']\n",
    "    # Moving average\n",
    "    if len(results) >= 20:\n",
    "        ma = np.convolve(results, np.ones(20)/20, mode='valid')\n",
    "        ax1.plot(range(19, len(results)), ma, label=exp_config['name'], linewidth=2)\n",
    "ax1.set_title('Learning Curves Comparison', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Episode')\n",
    "ax1.set_ylabel('Reward (MA-20)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Final performance comparison\n",
    "ax2 = axes[0, 1]\n",
    "final_perfs = [np.mean(exp['results'][-10:]) for exp in experiments.values()]\n",
    "names = [exp['name'] for exp in experiments.values()]\n",
    "bars = ax2.bar(names, final_perfs, color=['lightblue', 'lightgreen', 'lightcoral'])\n",
    "ax2.set_title('Final Performance (Last 10 Episodes)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Average Reward')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.1f}', ha='center', va='bottom')\n",
    "\n",
    "# 3. Distribution comparison\n",
    "ax3 = axes[1, 0]\n",
    "data_for_boxplot = [exp['results'] for exp in experiments.values()]\n",
    "ax3.boxplot(data_for_boxplot, labels=names)\n",
    "ax3.set_title('Reward Distribution', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Reward')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Statistical summary\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "summary_text = \"Experiment Summary\\n\" + \"=\"*40 + \"\\n\\n\"\n",
    "for exp_name, exp_config in experiments.items():\n",
    "    results = exp_config['results']\n",
    "    summary_text += f\"{exp_config['name']}:\\n\"\n",
    "    summary_text += f\"  Mean: {np.mean(results):.2f}\\n\"\n",
    "    summary_text += f\"  Std:  {np.std(results):.2f}\\n\"\n",
    "    summary_text += f\"  Max:  {np.max(results):.2f}\\n\\n\"\n",
    "\n",
    "ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes,\n",
    "         fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    "plt.suptitle('Experiment Comparison Dashboard', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/training/experiment_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Comparison visualization created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fa31e5",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Document your findings here:\n",
    "\n",
    "1. **Best Configuration**: [Fill in based on results]\n",
    "2. **Key Insights**: [Your observations]\n",
    "3. **Recommendations**: [Next steps]\n",
    "\n",
    "### Notes:\n",
    "- Add any additional observations\n",
    "- Document unexpected behaviors\n",
    "- Plan future experiments"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
